// client/context/callcontext.jsx

import { createContext, useContext, useState, useRef, useEffect } from 'react';
import { toast } from 'react-hot-toast';

// Detect mobile and WebView environment
const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
const isWebView = window.navigator.standalone || 
                  window.matchMedia('(display-mode: standalone)').matches ||
                  /wv|WebView/i.test(navigator.userAgent) ||
                  (!window.chrome && navigator.userAgent.includes('Android'));

export const CallContext = createContext();

// Metered.ca API Key for dynamic TURN credentials
const METERED_API_KEY = '737289ed2449406c8447cdbfb76f3848d6b6';
const METERED_API_URL = 'https://hide-in.metered.live/api/v1/turn/credentials';

// STUN servers (for NAT discovery) - Multiple for redundancy
const STUN_SERVERS = [
  { urls: 'stun:stun.relay.metered.ca:80' },
  { urls: 'stun:stun.l.google.com:19302' },
  { urls: 'stun:stun1.l.google.com:19302' }
];

// Static TURN servers (fallback if API fails)
// Using your Metered.ca credentials
const STATIC_TURN_SERVERS = [
  {
    urls: 'turn:us-west.relay.metered.ca:80',
    username: '3bd0a70f90417bcc4c8a9897',
    credential: 'w/s3uy0+NfQ3rIpc'
  },
  {
    urls: 'turn:us-west.relay.metered.ca:80?transport=tcp',
    username: '3bd0a70f90417bcc4c8a9897',
    credential: 'w/s3uy0+NfQ3rIpc'
  },
  {
    urls: 'turn:us-west.relay.metered.ca:443',
    username: '3bd0a70f90417bcc4c8a9897',
    credential: 'w/s3uy0+NfQ3rIpc'
  },
  {
    urls: 'turns:us-west.relay.metered.ca:443?transport=tcp',
    username: '3bd0a70f90417bcc4c8a9897',
    credential: 'w/s3uy0+NfQ3rIpc'
  }
];

// Function to fetch dynamic TURN credentials from Metered.ca API
const fetchTurnCredentials = async () => {
  try {
    console.log('üîÑ Fetching TURN credentials from Metered.ca API...');
    const response = await fetch(`${METERED_API_URL}?apiKey=${METERED_API_KEY}`);
    
    if (!response.ok) {
      throw new Error(`API request failed: ${response.status}`);
    }
    
    const iceServers = await response.json();
    console.log('‚úÖ TURN credentials fetched successfully');
    return iceServers;
  } catch (error) {
    console.warn('‚ö†Ô∏è Failed to fetch TURN credentials from API, using static credentials:', error);
    return null;
  }
};

// Initialize ICE servers with static credentials (will be updated with dynamic if available)
let ICE_SERVERS = {
  iceServers: [
    ...STUN_SERVERS,
    ...STATIC_TURN_SERVERS
  ],
  iceCandidatePoolSize: 10
};

// Fetch dynamic credentials on initialization (non-blocking)
fetchTurnCredentials().then(dynamicServers => {
  if (dynamicServers && Array.isArray(dynamicServers)) {
    console.log('‚úÖ Using dynamic TURN credentials from API');
    ICE_SERVERS = {
      iceServers: [
        ...STUN_SERVERS,
        ...dynamicServers
      ],
      iceCandidatePoolSize: 10
    };
  } else {
    console.log('‚ÑπÔ∏è Using static TURN credentials');
  }
}).catch(err => {
  console.warn('‚ö†Ô∏è Using static TURN credentials as fallback');
});

export const CallContextProvider = ({ children, socket }) => {
  const [incomingCall, setIncomingCall] = useState(null);
  const [activeCall, setActiveCall] = useState(null);
  const [callStatus, setCallStatus] = useState('idle'); // idle, calling, ringing, active, ended
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoEnabled, setIsVideoEnabled] = useState(false);
  
  const localStreamRef = useRef(null);
  const remoteStreamRef = useRef(null);
  const peerConnectionRef = useRef(null);
  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const callTimerRef = useRef(null);
  const callStatusRef = useRef('idle');
  const audioContextRef = useRef(null);
  const audioSourceRef = useRef(null);
  const reconnectAttemptsRef = useRef(0);
  const maxReconnectAttempts = 3;
  const trackMonitorIntervalRef = useRef(null);
  const [callDuration, setCallDuration] = useState(0);

  // Effect to ensure remote audio plays when stream is available
  useEffect(() => {
    if (activeCall) {
      // Function to check and attach stream if ref becomes available
      const checkAndAttachStream = () => {
        if (remoteVideoRef.current && remoteStreamRef.current) {
          const audio = remoteVideoRef.current;
          
          // If audio doesn't have the stream, attach it
          if (!audio.srcObject || audio.srcObject !== remoteStreamRef.current) {
            console.log('üîó Attaching stored stream to audio element');
            audio.srcObject = remoteStreamRef.current;
            audio.muted = false;
            audio.volume = 1.0;
          }
          
          // Check if stream is available and try to play
          if (audio.srcObject) {
            audio.muted = false;
            audio.volume = 1.0;
            
            // Try to play audio
            const tryPlay = () => {
              if (audio.srcObject && audio.readyState >= 2) {
                audio.play().then(() => {
                  console.log('‚úÖ Remote audio playing via useEffect');
                }).catch(err => {
                  console.log('Audio play attempt:', err);
                });
              }
            };
            
            tryPlay();
            
            // Also try when audio can play
            audio.addEventListener('canplay', tryPlay, { once: true });
            audio.addEventListener('loadedmetadata', tryPlay, { once: true });
            
            return () => {
              audio.removeEventListener('canplay', tryPlay);
              audio.removeEventListener('loadedmetadata', tryPlay);
            };
          }
        }
      };
      
      // Check immediately
      let cleanup = checkAndAttachStream();
      
      // Also check after delays (in case ref becomes available later)
      const timeouts = [
        setTimeout(() => { cleanup = checkAndAttachStream(); }, 100),
        setTimeout(() => { cleanup = checkAndAttachStream(); }, 500),
        setTimeout(() => { cleanup = checkAndAttachStream(); }, 1000),
        setTimeout(() => { cleanup = checkAndAttachStream(); }, 2000)
      ];
      
      return () => {
        if (cleanup) cleanup();
        timeouts.forEach(clearTimeout);
      };
    }
  }, [activeCall]);

  // Initialize socket listeners
  useEffect(() => {
    if (!socket) return;

    const handleIncomingCall = (data) => {
      console.log('üìû Incoming call:', data);
      setIncomingCall(data);
      setCallStatus('ringing');
      callStatusRef.current = 'ringing';
      
      // Play ringtone (optional)
      // You can add a ringtone audio file here
    };

    const handleCallAccepted = (data) => {
      console.log('‚úÖ Call accepted:', data);
      if (callStatusRef.current === 'calling') {
        setCallStatus('active');
        callStatusRef.current = 'active';
        setActiveCall(data);
        setIncomingCall(null);
        startCallTimer();
      }
    };

    const handleCallRejected = (data) => {
      console.log('‚ùå Call rejected:', data);
      // Reset call state without calling endCall to avoid cleanup issues
      setActiveCall(null);
      setIncomingCall(null);
      setCallStatus('idle');
      callStatusRef.current = 'idle';
      stopCallTimer();
      toast.error('Call rejected');
    };

    const handleCallEnded = (data) => {
      console.log('üì¥ Call ended:', data);
      // Reset call state
      setActiveCall(null);
      setIncomingCall(null);
      setCallStatus('idle');
      callStatusRef.current = 'idle';
      stopCallTimer();
      toast('Call ended', { icon: 'üì¥' });
    };

    const handleCallAnswer = (data) => {
      console.log('üìû Call answered:', data);
      if (callStatusRef.current === 'calling') {
        setCallStatus('active');
        callStatusRef.current = 'active';
        setActiveCall(prev => prev || data);
        setIncomingCall(null);
        startCallTimer();
      }
    };

    const handleICE = async (data) => {
      console.log('üßä Received ICE candidate from:', data.from);
      if (peerConnectionRef.current && data.candidate) {
        try {
          // Check if peer connection is in valid state
          if (peerConnectionRef.current.signalingState === 'closed') {
            console.warn('‚ö†Ô∏è Cannot add ICE candidate: peer connection is closed');
            return;
          }
          
          const candidate = new RTCIceCandidate(data.candidate);
          await peerConnectionRef.current.addIceCandidate(candidate);
          console.log('‚úÖ ICE candidate added successfully');
        } catch (error) {
          // Don't log error if candidate was already added (common and harmless)
          if (error.message && !error.message.includes('already been added')) {
            console.error('Error adding ICE candidate:', error);
          }
        }
      } else {
        console.warn('‚ö†Ô∏è Received ICE candidate but peer connection or candidate missing');
      }
    };

    const handleOffer = async (data) => {
      console.log('üì• Received offer:', data);
      // This is handled in acceptCall, but we can also handle it here if needed
      // The offer is already in incomingCall state
    };

    const handleAnswer = async (data) => {
      console.log('üì• Received answer:', data);
      if (peerConnectionRef.current) {
        try {
          const pc = peerConnectionRef.current;
          const signalingState = pc.signalingState;
          
          console.log('üîß Current signaling state:', signalingState);
          
          // Only set remote description if we're in the correct state
          // We should be in "have-local-offer" state when receiving an answer
          if (signalingState === 'have-local-offer') {
            await pc.setRemoteDescription(new RTCSessionDescription(data.answer));
            console.log('‚úÖ Remote description (answer) set successfully');
            
            setCallStatus('active');
            callStatusRef.current = 'active';
            reconnectAttemptsRef.current = 0; // Reset reconnect attempts on successful answer
            startCallTimer();
            
            // Clear call timeout if exists
            if (pc._callTimeout) {
              clearTimeout(pc._callTimeout);
              pc._callTimeout = null;
            }
            
            // Ensure remote audio is ready to play when stream arrives
            setTimeout(() => {
              if (remoteVideoRef.current) {
                remoteVideoRef.current.muted = false;
                if (remoteVideoRef.current.srcObject) {
                  remoteVideoRef.current.play().catch(err => {
                    console.log('Remote audio play attempt after answer:', err);
                  });
                }
              }
            }, 500);
          } else if (signalingState === 'stable') {
            // Already processed this answer or connection is already established
            console.log('‚ÑπÔ∏è Answer received but signaling state is already stable - ignoring duplicate answer');
          } else {
            console.warn('‚ö†Ô∏è Cannot set remote description: wrong signaling state', signalingState);
            console.warn('‚ö†Ô∏è Expected state: have-local-offer, got:', signalingState);
          }
        } catch (error) {
          console.error('Error handling answer:', error);
          // If it's a state error, log it but don't crash
          if (error.name === 'InvalidStateError') {
            console.warn('‚ö†Ô∏è Invalid state error - answer may have been processed already');
          } else {
            throw error;
          }
        }
      }
    };

    const handleRestartIce = async (data) => {
      console.log('üîÑ Received ICE restart offer:', data);
      if (peerConnectionRef.current && data.sdp) {
        try {
          await peerConnectionRef.current.setRemoteDescription(new RTCSessionDescription(data.sdp));
          const answer = await peerConnectionRef.current.createAnswer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
          await peerConnectionRef.current.setLocalDescription(answer);
          
          const targetUserId = activeCall?.userId || incomingCall?.from;
          if (targetUserId && socket) {
            socket.emit('restart-ice-answer', {
              to: targetUserId,
              sdp: answer
            });
            console.log('üì§ Sent ICE restart answer');
          }
        } catch (error) {
          console.error('Error handling ICE restart:', error);
        }
      }
    };

    const handleRestartIceAnswer = async (data) => {
      console.log('üì• Received ICE restart answer:', data);
      if (peerConnectionRef.current && data.sdp) {
        try {
          const pc = peerConnectionRef.current;
          const signalingState = pc.signalingState;
          
          console.log('üîß Current signaling state for ICE restart answer:', signalingState);
          
          // Should be in "have-local-offer" state when receiving ICE restart answer
          if (signalingState === 'have-local-offer' || signalingState === 'have-remote-offer') {
            await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
            console.log('‚úÖ ICE restart answer processed');
          } else if (signalingState === 'stable') {
            console.log('‚ÑπÔ∏è ICE restart answer received but state is stable - may be duplicate');
          } else {
            console.warn('‚ö†Ô∏è Cannot set ICE restart answer: wrong signaling state', signalingState);
          }
        } catch (error) {
          console.error('Error handling ICE restart answer:', error);
          if (error.name === 'InvalidStateError') {
            console.warn('‚ö†Ô∏è Invalid state error - ICE restart answer may have been processed already');
          }
        }
      }
    };

    const handleRenegotiate = async (data) => {
      console.log('üîÑ Received renegotiation offer:', data);
      if (peerConnectionRef.current && data.sdp) {
        try {
          const pc = peerConnectionRef.current;
          const signalingState = pc.signalingState;
          
          console.log('üîß Current signaling state for renegotiation:', signalingState);
          
          // Should be in "stable" state when receiving a renegotiation offer
          if (signalingState === 'stable' || signalingState === 'have-local-offer') {
            await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
            const answer = await pc.createAnswer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
            await pc.setLocalDescription(answer);
            
            const targetUserId = activeCall?.userId || incomingCall?.from;
            if (targetUserId && socket) {
              socket.emit('renegotiate-answer', {
                to: targetUserId,
                answer: answer
              });
              console.log('üì§ Sent renegotiation answer');
            }
          } else {
            console.warn('‚ö†Ô∏è Cannot handle renegotiation: wrong signaling state', signalingState);
          }
        } catch (error) {
          console.error('Error handling renegotiation:', error);
          if (error.name === 'InvalidStateError') {
            console.warn('‚ö†Ô∏è Invalid state error - renegotiation offer may have been processed already');
          }
        }
      }
    };

    const handleRenegotiateAnswer = async (data) => {
      console.log('üì• Received renegotiation answer:', data);
      if (peerConnectionRef.current && data.sdp) {
        try {
          const pc = peerConnectionRef.current;
          const signalingState = pc.signalingState;
          
          console.log('üîß Current signaling state for renegotiation answer:', signalingState);
          
          // Should be in "have-local-offer" state when receiving renegotiation answer
          if (signalingState === 'have-local-offer' || signalingState === 'have-remote-offer') {
            await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
            console.log('‚úÖ Renegotiation answer processed');
          } else if (signalingState === 'stable') {
            console.log('‚ÑπÔ∏è Renegotiation answer received but state is stable - may be duplicate');
          } else {
            console.warn('‚ö†Ô∏è Cannot set renegotiation answer: wrong signaling state', signalingState);
          }
        } catch (error) {
          console.error('Error handling renegotiation answer:', error);
          if (error.name === 'InvalidStateError') {
            console.warn('‚ö†Ô∏è Invalid state error - renegotiation answer may have been processed already');
          }
        }
      }
    };

    socket.on('incoming-call', handleIncomingCall);
    socket.on('call-accepted', handleCallAccepted);
    socket.on('call-rejected', handleCallRejected);
    socket.on('call-ended', handleCallEnded);
    socket.on('call-answer', handleAnswer); // This handles the WebRTC answer
    socket.on('ice-candidate', handleICE);
    socket.on('restart-ice', handleRestartIce);
    socket.on('restart-ice-answer', handleRestartIceAnswer);
    socket.on('renegotiate', handleRenegotiate);
    socket.on('renegotiate-answer', handleRenegotiateAnswer);

    return () => {
      socket.off('incoming-call', handleIncomingCall);
      socket.off('call-accepted', handleCallAccepted);
      socket.off('call-rejected', handleCallRejected);
      socket.off('call-ended', handleCallEnded);
      socket.off('call-answer', handleAnswer);
      socket.off('ice-candidate', handleICE);
      socket.off('restart-ice', handleRestartIce);
      socket.off('restart-ice-answer', handleRestartIceAnswer);
      socket.off('renegotiate', handleRenegotiate);
      socket.off('renegotiate-answer', handleRenegotiateAnswer);
    };
  }, [socket]);

  // Create peer connection
  const createPeerConnection = async () => {
    // Try to get fresh TURN credentials if available
    let iceConfig = ICE_SERVERS;
    try {
      const dynamicServers = await fetchTurnCredentials();
      if (dynamicServers && Array.isArray(dynamicServers)) {
        iceConfig = {
          iceServers: [
            ...STUN_SERVERS,
            ...dynamicServers
          ],
          iceCandidatePoolSize: 10
        };
        console.log('‚úÖ Using fresh TURN credentials from API');
      }
    } catch (err) {
      console.log('‚ÑπÔ∏è Using cached TURN credentials');
    }
    
    console.log('üîß Creating RTCPeerConnection with configuration:', {
      iceServers: iceConfig.iceServers.length,
      iceCandidatePoolSize: iceConfig.iceCandidatePoolSize,
      turnServers: iceConfig.iceServers.filter(s => s.urls.includes('turn:')).length
    });
    
    const pc = new RTCPeerConnection(iceConfig);
    
    // Add local stream tracks
    if (localStreamRef.current) {
      const localStream = localStreamRef.current;
      localStream.getTracks().forEach(track => {
        console.log('üé§ Adding local track:', track.kind, track.id, 'enabled:', track.enabled);
        pc.addTrack(track, localStream);
      });
      console.log('‚úÖ Local stream tracks added to peer connection');
    } else {
      console.warn('‚ö†Ô∏è No local stream available when creating peer connection');
    }

    // Handle remote stream
    pc.ontrack = (event) => {
      console.log('üìπ Received remote stream event');
      console.log('üìπ Track kind:', event.track.kind);
      console.log('üìπ Track id:', event.track.id);
      console.log('üìπ Track enabled:', event.track.enabled);
      console.log('üìπ Track readyState:', event.track.readyState);
      
      if (event.streams && event.streams.length > 0) {
        const remoteStream = event.streams[0];
        const tracks = remoteStream.getTracks();
        console.log('üìπ Remote stream received with', tracks.length, 'tracks');
        
        // Log audio track details
        tracks.forEach(track => {
          if (track.kind === 'audio') {
            console.log('üéµ Remote audio track:', {
              id: track.id,
              enabled: track.enabled,
              muted: track.muted,
              readyState: track.readyState
            });
          }
        });
        
        // Ensure all tracks are enabled and monitor for recovery
        tracks.forEach(track => {
          if (track.kind === 'audio') {
            track.enabled = true;
            console.log('üéµ Audio track enabled:', track.id, 'enabled:', track.enabled, 'muted:', track.muted, 'readyState:', track.readyState);
            
            // Monitor track state for recovery
            track.onended = () => {
              console.warn('‚ö†Ô∏è Audio track ended! Attempting recovery...');
              // Track ended - try to recover by checking if we can get a new stream
              recoverTrack(track);
            };
            
            track.onmute = () => {
              console.warn('‚ö†Ô∏è Audio track muted!');
            };
            
            track.onunmute = () => {
              console.log('‚úÖ Audio track unmuted');
            };
            
            // Monitor track readyState changes and auto-recover
            const checkTrackState = setInterval(() => {
              if (track.readyState === 'ended') {
                console.warn('‚ö†Ô∏è Track readyState changed to ended:', track.id);
                
                // Always attempt recovery when track ends (don't wait for connection to fail)
                // This ensures audio continues even if one track ends
                const stream = remoteStreamRef.current;
                if (stream) {
                  const liveTracks = stream.getAudioTracks().filter(t => t.readyState === 'live' && t.id !== track.id);
                  if (liveTracks.length === 0) {
                    // No other live tracks - attempt recovery
                    console.warn('‚ö†Ô∏è All tracks ended, attempting recovery...');
                    clearInterval(checkTrackState);
                    recoverTrack(track);
                  } else {
                    // Other tracks are live - just reattach those
                    console.log('‚ÑπÔ∏è Track ended but other tracks are live, reattaching...');
                    if (remoteVideoRef.current) {
                      const newStream = new MediaStream(liveTracks);
                      remoteStreamRef.current = newStream;
                      remoteVideoRef.current.srcObject = newStream;
                      remoteVideoRef.current.muted = false;
                      remoteVideoRef.current.volume = 1.0;
                      remoteVideoRef.current.play().catch(console.warn);
                    }
                  }
                } else {
                  clearInterval(checkTrackState);
                  recoverTrack(track);
                }
              } else if (track.readyState === 'live') {
                // Track is live - log occasionally
                if (Math.random() < 0.05) { // 5% chance
                  console.log('‚úÖ Remote audio active: track is live');
                }
              }
            }, 3000); // Check every 3 seconds
            
            // Store interval for cleanup
            track._monitorInterval = checkTrackState;
          }
        });
        
        // Monitor stream active state (WebView/APK compatible - less aggressive)
        // Note: In WebView, stream.active might be false even when tracks are live
        const checkStreamActive = setInterval(() => {
          // First check if tracks are actually live (more reliable than stream.active in WebView)
          const liveTracks = remoteStream.getTracks().filter(t => t.readyState === 'live');
          const hasLiveTracks = liveTracks.length > 0;
          
          // In WebView/APK, stream.active can be false even when working
          // So we prioritize track state over stream.active
          if (!remoteStream.active && !hasLiveTracks) {
            // Both stream and tracks are inactive - check connection state
            if (peerConnectionRef.current) {
              const pcState = peerConnectionRef.current.connectionState;
              const iceState = peerConnectionRef.current.iceConnectionState;
              
              // Only recover if connection is actually failed/disconnected
              if (pcState === 'failed' || pcState === 'disconnected' || 
                  iceState === 'failed' || iceState === 'disconnected') {
                console.warn('‚ö†Ô∏è Remote stream and tracks inactive, connection failed - attempting recovery...');
                clearInterval(checkStreamActive);
                recoverStream();
              } else if (pcState === 'new' || pcState === 'connecting' || iceState === 'checking') {
                // Connection is still being established, don't recover
                return;
              } else if (pcState === 'connected' && iceState === 'connected') {
                // Connection is good but stream/tracks inactive - wait longer before recovering
                setTimeout(() => {
                  const stillInactive = !remoteStream.active && 
                    remoteStream.getTracks().filter(t => t.readyState === 'live').length === 0;
                  if (stillInactive) {
                    console.warn('‚ö†Ô∏è Stream still inactive after waiting, attempting recovery...');
                    clearInterval(checkStreamActive);
                    recoverStream();
                  }
                }, 10000); // Wait 10 seconds for WebView/APK
              }
            }
          } else if (!remoteStream.active && hasLiveTracks) {
            // Stream inactive but tracks are live - this is normal in WebView/APK
            // Don't log or recover, just silently continue
          }
        }, 10000); // Check every 10 seconds for WebView/APK compatibility
        
        remoteStream._activeCheck = checkStreamActive;
        
        // Store stream in ref for later use
        remoteStreamRef.current = remoteStream;
        
        // Function to attach stream to audio element
        const attachStreamToAudio = () => {
          if (remoteVideoRef.current) {
            // Stop any existing stream tracks (but keep the stream object)
            if (remoteVideoRef.current.srcObject) {
              const oldTracks = remoteVideoRef.current.srcObject.getTracks();
              oldTracks.forEach(track => {
                if (track.readyState !== 'ended') {
                  track.stop();
                }
              });
            }
            
            // Create a new MediaStream with the tracks to ensure it stays alive
            // Important for WebView/APK: Create new stream to prevent premature ending
            const newStream = new MediaStream();
            tracks.forEach(track => {
              if (track.readyState !== 'ended') {
                newStream.addTrack(track);
                // Ensure track stays enabled
                track.enabled = true;
              }
            });
            
            // Store the new stream reference
            remoteStreamRef.current = newStream;
            remoteVideoRef.current.srcObject = newStream;
            
            // For WebView/APK: Keep reference to original stream tracks to prevent garbage collection
            if (!remoteStream._originalTracks) {
              remoteStream._originalTracks = tracks;
            }
          
          // Ensure remote audio is NOT muted and volume is set
          remoteVideoRef.current.muted = false;
          remoteVideoRef.current.volume = 1.0;
          
          // Set attributes for proper playback
          remoteVideoRef.current.setAttribute('playsinline', 'true');
          remoteVideoRef.current.setAttribute('webkit-playsinline', 'true');
          remoteVideoRef.current.setAttribute('autoplay', 'true');
          
          console.log('üîä Audio element configured:', {
            muted: remoteVideoRef.current.muted,
            volume: remoteVideoRef.current.volume,
            srcObject: !!remoteVideoRef.current.srcObject,
            readyState: remoteVideoRef.current.readyState
          });
          
          // Force play audio - works for both desktop and mobile
          // Try Web Audio API first (more reliable), fallback to HTML audio
          const playRemoteAudio = () => {
            if (!remoteVideoRef.current || !remoteVideoRef.current.srcObject) {
              console.warn('‚ö†Ô∏è Cannot play: audio element or stream missing');
              return;
            }
            
            const audio = remoteVideoRef.current;
            const stream = audio.srcObject;
            const audioTracks = stream.getAudioTracks();
            
            // Check track state
            if (audioTracks.length === 0) {
              console.warn('‚ö†Ô∏è No audio tracks in stream!');
              return;
            }
            
            const audioTrack = audioTracks[0];
            console.log('üéµ Audio track state:', {
              enabled: audioTrack.enabled,
              muted: audioTrack.muted,
              readyState: audioTrack.readyState,
              id: audioTrack.id,
              streamActive: stream.active
            });
            
            // Ensure track is enabled (critical for WebView/APK)
            if (!audioTrack.enabled) {
              console.log('üîß Enabling audio track...');
              audioTrack.enabled = true;
            }
            
            // For WebView/APK: Ensure stream doesn't get garbage collected
            // Keep a reference to prevent premature stream ending
            if (isWebView || isMobile) {
              // Store stream reference globally to prevent GC
              if (!window._activeWebRTCStreams) {
                window._activeWebRTCStreams = new Set();
              }
              window._activeWebRTCStreams.add(stream);
              
              // Also store tracks to prevent them from being collected
              audioTracks.forEach(track => {
                if (!track._webViewKeepAlive) {
                  track._webViewKeepAlive = true;
                }
              });
            }
            
            // Try Web Audio API approach (more reliable for MediaStreams)
            try {
              // Create or reuse AudioContext
              if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
                audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
              }
              
              const audioContext = audioContextRef.current;
              
              // Resume audio context if suspended (required by some browsers)
              if (audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                  console.log('‚úÖ AudioContext resumed');
                });
              }
              
              // Create media stream source
              if (audioSourceRef.current) {
                audioSourceRef.current.disconnect();
              }
              
              audioSourceRef.current = audioContext.createMediaStreamSource(stream);
              const gainNode = audioContext.createGain();
              gainNode.gain.value = 1.0; // Full volume
              
              audioSourceRef.current.connect(gainNode);
              gainNode.connect(audioContext.destination);
              
              console.log('‚úÖ Using Web Audio API for playback');
              
              // Also set up HTML audio element as backup
              audio.muted = false;
              audio.volume = 1.0;
              audio.play().then(() => {
                console.log('‚úÖ HTML audio also playing (backup)');
              }).catch(err => {
                console.log('HTML audio play failed (using Web Audio API):', err);
              });
              
            } catch (webAudioError) {
              console.warn('‚ö†Ô∏è Web Audio API failed, using HTML audio:', webAudioError);
              
              // Fallback to HTML audio element
              audio.muted = false;
              audio.volume = 1.0;
              
              console.log('‚ñ∂Ô∏è Attempting to play remote audio via HTML element...');
              audio.play().then(() => {
                console.log('‚úÖ Remote audio playing successfully!');
                console.log('üîä Audio state:', {
                  paused: audio.paused,
                  muted: audio.muted,
                  volume: audio.volume,
                  readyState: audio.readyState,
                  trackEnabled: audioTrack.enabled,
                  trackMuted: audioTrack.muted
                });
                
                // Monitor if audio pauses unexpectedly
                const checkPlaying = setInterval(() => {
                  if (audio.paused && stream.active && audioTrack.readyState === 'live') {
                    console.warn('‚ö†Ô∏è Audio paused unexpectedly, attempting to resume...');
                    audio.play().catch(err => {
                      console.warn('Failed to resume:', err);
                    });
                  }
                }, 1000);
                
                // Store interval to clear later
                audio._playingCheck = checkPlaying;
              }).catch(err => {
                console.warn('‚ö†Ô∏è Auto-play prevented, will retry:', err);
                // Retry on user interaction
                const retryPlay = () => {
                  if (remoteVideoRef.current && remoteVideoRef.current.srcObject) {
                    const audio = remoteVideoRef.current;
                    audio.muted = false;
                    audio.volume = 1.0;
                    console.log('üîÑ Retrying audio play on user interaction...');
                    audio.play().then(() => {
                      console.log('‚úÖ Remote audio playing after user interaction!');
                    }).catch(console.error);
                  }
                  document.removeEventListener('touchstart', retryPlay);
                  document.removeEventListener('click', retryPlay);
                  document.removeEventListener('touchend', retryPlay);
                };
                document.addEventListener('touchstart', retryPlay, { once: true });
                document.addEventListener('click', retryPlay, { once: true });
                document.addEventListener('touchend', retryPlay, { once: true });
              });
            }
          };
          
          // Try to play immediately
          setTimeout(playRemoteAudio, 100);
          
          // Also try when metadata is loaded
          remoteVideoRef.current.onloadedmetadata = () => {
            console.log('üìã Metadata loaded, attempting play...');
            playRemoteAudio();
          };
          
          // Also try on canplay event
          remoteVideoRef.current.oncanplay = () => {
            console.log('‚ñ∂Ô∏è Can play, attempting play...');
            playRemoteAudio();
          };
          
          // Also try on play event
          remoteVideoRef.current.onplay = () => {
            console.log('üéµ Remote audio onplay event fired');
          };
          
          // Log when audio starts/stops
          remoteVideoRef.current.onplaying = () => {
            console.log('üéµ Remote audio is now playing!');
          };
          
          remoteVideoRef.current.onpause = () => {
            console.warn('‚è∏Ô∏è Remote audio paused');
            // Try to resume if stream is still active
            if (remoteVideoRef.current && remoteVideoRef.current.srcObject) {
              const stream = remoteVideoRef.current.srcObject;
              if (stream.active) {
                const tracks = stream.getAudioTracks();
                if (tracks.length > 0 && tracks[0].readyState === 'live') {
                  console.log('üîÑ Attempting to resume paused audio...');
                  setTimeout(() => {
                    if (remoteVideoRef.current && !remoteVideoRef.current.paused) return;
                    remoteVideoRef.current?.play().catch(err => {
                      console.warn('Failed to resume:', err);
                    });
                  }, 100);
                }
              }
            }
          };
          
          remoteVideoRef.current.onerror = (e) => {
            console.error('‚ùå Remote audio error:', e);
          };
          
          // Monitor stream active state
          if (remoteStream) {
            const checkStreamActive = setInterval(() => {
              if (!remoteStream.active) {
                console.warn('‚ö†Ô∏è Remote stream became inactive!');
                clearInterval(checkStreamActive);
              }
            }, 2000);
            
            // Store interval reference
            remoteStream._activeCheck = checkStreamActive;
          }
          
          return true; // Successfully attached
        } else {
          console.warn('‚ö†Ô∏è remoteVideoRef.current is null, will retry...');
          return false; // Not ready yet
        }
      };
      
      // Try to attach immediately
      if (!attachStreamToAudio()) {
        // If ref is not ready, retry after a short delay
        // This can happen if the modal hasn't rendered yet
        let retryCount = 0;
        const maxRetries = 10;
        const retryInterval = setInterval(() => {
          retryCount++;
          if (attachStreamToAudio() || retryCount >= maxRetries) {
            clearInterval(retryInterval);
            if (retryCount >= maxRetries) {
              console.error('‚ùå Failed to attach stream after', maxRetries, 'retries');
            }
          }
        }, 200);
      }
      } else {
        console.warn('‚ö†Ô∏è No streams in event');
      }
    };

    // Handle ICE candidates
    pc.onicecandidate = (event) => {
      if (event.candidate && socket) {
        const targetUserId = activeCall?.userId || incomingCall?.from;
        if (targetUserId) {
          // Parse candidate type from candidate string
          const candidateStr = event.candidate.candidate;
          let candidateType = 'unknown';
          if (candidateStr.includes('typ host')) {
            candidateType = 'host';
          } else if (candidateStr.includes('typ srflx')) {
            candidateType = 'srflx';
          } else if (candidateStr.includes('typ relay')) {
            candidateType = 'relay';
          } else if (candidateStr.includes('typ prflx')) {
            candidateType = 'prflx';
          }
          
          console.log(`üßä Sending ICE candidate (type: ${candidateType}):`, {
            to: targetUserId,
            candidate: candidateStr.substring(0, 100) + '...',
            sdpMLineIndex: event.candidate.sdpMLineIndex,
            sdpMid: event.candidate.sdpMid,
            type: candidateType
          });
          
          // Log relay candidates specifically (TURN usage)
          if (candidateType === 'relay') {
            console.log('üîπ ICE candidate type: relay (TURN server active)');
          }
          
          socket.emit('ice-candidate', {
            to: targetUserId,
            candidate: event.candidate
          });
        } else {
          console.warn('‚ö†Ô∏è No target user ID for ICE candidate');
        }
      } else if (!event.candidate) {
        console.log('üßä ICE gathering complete - no more candidates');
      }
    };
    
    // Log connection state changes
    pc.oniceconnectionstatechange = () => {
      console.log('üîå ICE connection state:', pc.iceConnectionState);
      
      // If connection fails, try to restart ICE automatically
      if (pc.iceConnectionState === 'failed') {
        console.warn('‚ö†Ô∏è ICE connection failed, attempting automatic ICE restart...');
        console.log('üîÑ Auto-recovery: ICE connection state failed');
        
        // Use attemptReconnection which handles ICE restart properly
        setTimeout(() => {
          if (pc.iceConnectionState === 'failed' && activeCall) {
            attemptReconnection();
          }
        }, 1000);
      }
      
      // Log connection quality
      if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
        console.log('‚úÖ ICE connection established successfully!');
        console.log('üîå ICE connection state: connected');
        
        // Get detailed connection stats to verify TURN usage
        pc.getStats().then(stats => {
          let selectedPair = null;
          let localCandidate = null;
          let remoteCandidate = null;
          let usingRelay = false;
          
          stats.forEach(report => {
            // Find selected candidate pair
            if (report.type === 'candidate-pair' && report.selected) {
              selectedPair = report;
              console.log('üìä Selected candidate pair:', {
                state: report.state,
                priority: report.priority,
                bytesReceived: report.bytesReceived,
                bytesSent: report.bytesSent
              });
            }
            
            // Find local candidate details
            if (report.type === 'local-candidate' && selectedPair && report.id === selectedPair.localCandidateId) {
              localCandidate = report;
              console.log('üì° Local candidate:', {
                type: report.candidateType,
                ip: report.ip,
                port: report.port,
                protocol: report.protocol
              });
              if (report.candidateType === 'relay') {
                usingRelay = true;
                console.log('üîπ Using TURN relay (local)');
              }
            }
            
            // Find remote candidate details
            if (report.type === 'remote-candidate' && selectedPair && report.id === selectedPair.remoteCandidateId) {
              remoteCandidate = report;
              console.log('üì° Remote candidate:', {
                type: report.candidateType,
                ip: report.ip,
                port: report.port,
                protocol: report.protocol
              });
              if (report.candidateType === 'relay') {
                usingRelay = true;
                console.log('üîπ Using TURN relay (remote)');
              }
            }
          });
          
          // Summary
          if (usingRelay) {
            console.log('‚úÖ Connection using TURN relay - Good for cross-network calls!');
          } else {
            console.log('‚ÑπÔ∏è Connection using direct P2P (no TURN relay)');
          }
        }).catch(err => {
          console.warn('Failed to get stats:', err);
        });
      } else if (pc.iceConnectionState === 'checking') {
        console.log('üîÑ ICE connection state: checking (gathering candidates...)');
      } else if (pc.iceConnectionState === 'disconnected') {
        console.warn('‚ö†Ô∏è ICE connection state: disconnected');
        console.log('üîÑ Attempting reconnection...');
        // Attempt to reconnect by restarting ICE
        attemptReconnection();
      } else if (pc.iceConnectionState === 'new') {
        console.log('üÜï ICE connection state: new');
      } else if (pc.iceConnectionState === 'checking') {
        console.log('üîÑ ICE connection state: checking (gathering candidates...)');
      }
    };
    
    pc.onicegatheringstatechange = () => {
      console.log('üßä ICE gathering state:', pc.iceGatheringState);
      
      if (pc.iceGatheringState === 'complete') {
        console.log('‚úÖ ICE gathering complete - all candidates collected');
      }
    };

    // Handle connection state changes
    pc.onconnectionstatechange = () => {
      console.log('üîå Connection state:', pc.connectionState);
      console.log('üîå Signaling state:', pc.signalingState);
      console.log('üîå ICE connection state:', pc.iceConnectionState);
      
      if (pc.connectionState === 'connected') {
        console.log('‚úÖ Peer connection established!');
        console.log('üéß Remote audio should be playing...');
        
        // Log connection details and verify audio flow
        pc.getStats().then(stats => {
          let hasRelay = false;
          let hasHost = false;
          let hasSrflx = false;
          let audioBytesReceived = 0;
          let audioBytesSent = 0;
          
          stats.forEach(report => {
            if (report.type === 'local-candidate' || report.type === 'remote-candidate') {
              if (report.candidateType === 'relay') {
                hasRelay = true;
                console.log('üîπ ICE candidate type: relay (TURN active)');
              }
              if (report.candidateType === 'host') hasHost = true;
              if (report.candidateType === 'srflx') hasSrflx = true;
            }
            
            // Check audio bytes flow
            if (report.type === 'inbound-rtp' && report.mediaType === 'audio') {
              audioBytesReceived = report.bytesReceived || 0;
            }
            if (report.type === 'outbound-rtp' && report.mediaType === 'audio') {
              audioBytesSent = report.bytesSent || 0;
            }
          });
          
          console.log('üìä Connection type summary:', {
            usingRelay: hasRelay,
            usingHost: hasHost,
            usingSrflx: hasSrflx,
            audioBytesReceived: audioBytesReceived,
            audioBytesSent: audioBytesSent,
            note: hasRelay 
              ? '‚úÖ Using TURN (relay) - Excellent for cross-network calls!' 
              : hasSrflx 
                ? '‚ÑπÔ∏è Using STUN (srflx) - May work for cross-network'
                : '‚ö†Ô∏è Using direct connection - May fail across different networks'
          });
          
          // Verify audio is flowing
          if (audioBytesReceived > 0) {
            console.log('‚úÖ Audio bytes flowing - receiving audio data');
          } else {
            console.warn('‚ö†Ô∏è No audio bytes received yet - audio may not be working');
          }
        }).catch(err => {
          console.warn('Failed to get connection stats:', err);
        });
        
        // When connected, ensure remote audio plays
        setTimeout(() => {
          if (remoteVideoRef.current && remoteVideoRef.current.srcObject) {
            remoteVideoRef.current.muted = false;
            remoteVideoRef.current.volume = 1.0;
            remoteVideoRef.current.play().then(() => {
              console.log('üéß Remote audio playing successfully!');
            }).catch(err => {
              console.log('Audio play on connection:', err);
            });
          }
        }, 500);
      } else if (pc.connectionState === 'connecting') {
        console.log('üîÑ Connection state: connecting (establishing connection...)');
      } else if (pc.connectionState === 'failed') {
        console.error('‚ùå Connection state: failed');
        console.error('‚ùå Connection failed! This may be a NAT/firewall issue.');
        console.error('üí° Try: 1) Check firewall settings 2) Verify TURN server 3) Check network');
        
        // Try ICE restart before giving up
        setTimeout(() => {
          if (peerConnectionRef.current && peerConnectionRef.current.connectionState === 'failed') {
            console.log('üîÑ Attempting ICE restart...');
            try {
              const pc = peerConnectionRef.current;
              // Check if restartIce is available and returns a Promise
              if (pc.restartIce && typeof pc.restartIce === 'function') {
                const restartPromise = pc.restartIce();
                if (restartPromise && typeof restartPromise.catch === 'function') {
                  restartPromise.catch(err => {
                    console.error('ICE restart failed:', err);
                    endCall();
                    toast.error('Call failed - Check network connection');
                  });
                } else {
                  // restartIce didn't return a Promise, handle gracefully
                  console.warn('‚ö†Ô∏è restartIce() did not return a Promise');
                  endCall();
                  toast.error('Call failed - Check network connection');
                }
              } else {
                console.warn('‚ö†Ô∏è restartIce() not available in this browser');
                endCall();
                toast.error('Call failed - Check network connection');
              }
            } catch (err) {
              console.error('Error calling restartIce:', err);
              endCall();
              toast.error('Call failed - Check network connection');
            }
          }
        }, 2000);
      } else if (pc.connectionState === 'disconnected') {
        console.warn('‚ö†Ô∏è Connection state: disconnected');
        console.log('üîÑ Attempting reconnection...');
        // Attempt to reconnect
        attemptReconnection();
      } else if (pc.connectionState === 'closed') {
        console.log('üîå Connection state: closed');
      } else if (pc.connectionState === 'new') {
        // "new" state is normal during initial setup, don't log or recover
        // This happens when peer connection is first created
      }
    };

    peerConnectionRef.current = pc;
    return pc;
  };

  // Attempt reconnection when connection fails or disconnects (with force renegotiation)
  const attemptReconnection = async () => {
    if (!peerConnectionRef.current || !socket || !activeCall) {
      return;
    }

    if (reconnectAttemptsRef.current >= maxReconnectAttempts) {
      console.error('‚ùå Max reconnection attempts reached, ending call');
      endCall();
      toast.error('Call disconnected - Unable to reconnect');
      return;
    }

    reconnectAttemptsRef.current++;
    console.log(`üîÑ Reconnection attempt ${reconnectAttemptsRef.current}/${maxReconnectAttempts}`);
    console.log('üîß Connection state:', peerConnectionRef.current.connectionState);
    console.log('üîß ICE connection state:', peerConnectionRef.current.iceConnectionState);

    try {
      const pc = peerConnectionRef.current;
      
      // Always use manual ICE restart with createOffer for better compatibility
      console.log('üîÑ Creating re-offer for ICE restart...');
      
      // Ensure we're in a stable state before creating offer
      if (pc.signalingState === 'stable' || pc.signalingState === 'have-local-offer' || pc.signalingState === 'have-remote-offer') {
        const offer = await pc.createOffer({ 
          iceRestart: true,
          offerToReceiveAudio: true,
          offerToReceiveVideo: false
        });
        await pc.setLocalDescription(offer);
        
        const targetUserId = activeCall.userId;
        if (targetUserId && socket) {
          socket.emit('restart-ice', {
            to: targetUserId,
            sdp: offer
          });
          console.log('üì§ Sent re-offer for ICE restart');
          toast('Reconnecting...', { icon: 'üîÑ' });
        }
      } else {
        console.warn('‚ö†Ô∏è Signaling state not ready for ICE restart:', pc.signalingState);
        // Wait and retry
        setTimeout(() => {
          if (peerConnectionRef.current && peerConnectionRef.current.connectionState !== 'connected') {
            attemptReconnection();
          }
        }, 2000);
      }
    } catch (error) {
      console.error('‚ùå Reconnection attempt failed:', error);
      // Wait before next attempt
      setTimeout(() => {
        if (peerConnectionRef.current && peerConnectionRef.current.connectionState !== 'connected') {
          attemptReconnection();
        }
      }, 3000);
    }
  };

  // Recover track when it ends (with automatic renegotiation)
  const recoverTrack = async (endedTrack) => {
    console.log('üîß Attempting track recovery for ended track:', endedTrack.id);
    
    if (!peerConnectionRef.current || !remoteStreamRef.current) {
      console.warn('‚ö†Ô∏è Cannot recover: peer connection or stream missing');
      return;
    }

    // Wait a bit for new tracks to potentially arrive (WebRTC might be switching tracks)
    await new Promise(resolve => setTimeout(resolve, 2000));

    // Check if peer connection has new tracks from receivers (most reliable)
    if (peerConnectionRef.current.getReceivers) {
      const receivers = peerConnectionRef.current.getReceivers();
      const receiverTracks = receivers
        .map(r => r.track)
        .filter(t => t && t.kind === 'audio' && t.readyState === 'live');
      
      if (receiverTracks.length > 0) {
        console.log('‚úÖ Found active tracks from receivers, reattaching...');
        if (remoteVideoRef.current) {
          const newStream = new MediaStream(receiverTracks);
          remoteStreamRef.current = newStream;
          remoteVideoRef.current.srcObject = newStream;
          remoteVideoRef.current.muted = false;
          remoteVideoRef.current.volume = 1.0;
          
          // Ensure tracks stay enabled
          receiverTracks.forEach(track => {
            track.enabled = true;
            // Monitor new tracks
            track.onended = () => {
              console.warn('‚ö†Ô∏è Recovered track ended, attempting recovery again...');
              recoverTrack(track);
            };
          });
          
          remoteVideoRef.current.play().then(() => {
            console.log('‚úÖ Recovered stream playing successfully');
            toast.success('Audio reconnected');
          }).catch(err => {
            console.warn('Failed to play recovered stream:', err);
          });
          return;
        }
      }
    }
    
    // Check if there are other active tracks in current stream
    const stream = remoteStreamRef.current;
    const audioTracks = stream.getAudioTracks();
    const activeTracks = audioTracks.filter(t => t.readyState === 'live' && t.id !== endedTrack.id);
    
    if (activeTracks.length > 0) {
      console.log('‚úÖ Found active tracks in stream, reattaching...');
      if (remoteVideoRef.current) {
        const newStream = new MediaStream(activeTracks);
        remoteStreamRef.current = newStream;
        remoteVideoRef.current.srcObject = newStream;
        remoteVideoRef.current.muted = false;
        remoteVideoRef.current.volume = 1.0;
        
        // Monitor tracks
        activeTracks.forEach(track => {
          track.enabled = true;
          track.onended = () => {
            console.warn('‚ö†Ô∏è Track ended, attempting recovery...');
            recoverTrack(track);
          };
        });
        
        remoteVideoRef.current.play().then(() => {
          console.log('‚úÖ Recovered stream playing');
        }).catch(err => {
          console.warn('Failed to play recovered stream:', err);
        });
      }
    } else {
        // Check connection state before attempting reconnection
        const pc = peerConnectionRef.current;
        const pcState = pc.connectionState;
        const iceState = pc.iceConnectionState;
        
        // Don't recover if connection is still being established
        if (pcState === 'new' || pcState === 'connecting' || iceState === 'checking' || iceState === 'new') {
          console.log('‚ÑπÔ∏è Connection still being established, waiting for tracks...');
          return;
        }
        
        if (pcState === 'connected' || pcState === 'connecting') {
          console.log('‚ÑπÔ∏è Connection still active, waiting for new tracks...');
          // Wait a bit more - new tracks might arrive
          setTimeout(() => {
            const stream = remoteStreamRef.current;
            if (stream) {
              const newTracks = stream.getAudioTracks().filter(t => t.readyState === 'live');
              if (newTracks.length > 0) {
                console.log('‚úÖ New tracks arrived, reattaching...');
                if (remoteVideoRef.current) {
                  const newStream = new MediaStream(newTracks);
                  remoteStreamRef.current = newStream;
                  remoteVideoRef.current.srcObject = newStream;
                  remoteVideoRef.current.muted = false;
                  remoteVideoRef.current.volume = 1.0;
                  remoteVideoRef.current.play().catch(console.warn);
                }
              } else {
                // Only attempt reconnection if connection is actually failing
                if (pcState === 'disconnected' || pcState === 'failed' || 
                    iceState === 'disconnected' || iceState === 'failed') {
                  console.warn('‚ö†Ô∏è No active tracks found and connection failed, attempting recovery...');
                  attemptReconnection();
                }
              }
            }
          }, 3000);
        } else {
          // Only reconnect if connection is actually failed/disconnected
          if (pcState === 'disconnected' || pcState === 'failed' || 
              iceState === 'disconnected' || iceState === 'failed') {
            console.warn('‚ö†Ô∏è No active tracks found, connection state:', pcState, 'ICE state:', iceState);
            attemptReconnection();
          }
        }
      }
  };

  // Recover stream when it becomes inactive (with force renegotiation)
  const recoverStream = async () => {
    console.log('üîß Attempting stream recovery...');
    
    if (!peerConnectionRef.current) {
      console.warn('‚ö†Ô∏è Cannot recover: peer connection missing');
      return;
    }

    const pc = peerConnectionRef.current;
    
    // First, check if we can get tracks from receivers
    if (pc.getReceivers) {
      const receivers = pc.getReceivers();
      const receiverTracks = receivers
        .map(r => r.track)
        .filter(t => t && t.kind === 'audio' && t.readyState === 'live');
      
      if (receiverTracks.length > 0) {
        console.log('‚úÖ Found live tracks in receivers, reattaching stream...');
        if (remoteVideoRef.current) {
          const newStream = new MediaStream(receiverTracks);
          remoteStreamRef.current = newStream;
          remoteVideoRef.current.srcObject = newStream;
          remoteVideoRef.current.muted = false;
          remoteVideoRef.current.volume = 1.0;
          
          receiverTracks.forEach(track => {
            track.enabled = true;
          });
          
          remoteVideoRef.current.play().then(() => {
            console.log('‚úÖ Stream recovered and playing');
            toast.success('Audio stream reconnected');
          }).catch(console.warn);
          return;
        }
      }
    }
    
    // If no tracks found, try to reconnect
    console.log('üîÑ No live tracks found, attempting ICE restart...');
    attemptReconnection();
  };

  // Re-capture local audio if track ends (with sender.replaceTrack for better compatibility)
  const reCaptureLocalAudio = async () => {
    console.log('üîÑ Re-capturing local audio...');
    
    try {
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          ...(isMobile && {
            sampleRate: 48000,
            channelCount: 1
          })
        },
        video: false
      };

      const newStream = await navigator.mediaDevices.getUserMedia(constraints);
      const newAudioTrack = newStream.getAudioTracks()[0];
      
      if (!newAudioTrack) {
        throw new Error('No audio track in new stream');
      }
      
      // Replace tracks using sender.replaceTrack (better than removeTrack + addTrack)
      if (peerConnectionRef.current && localStreamRef.current) {
        const senders = peerConnectionRef.current.getSenders();
        const audioSenders = senders.filter(sender => 
          sender.track && sender.track.kind === 'audio'
        );
        
        if (audioSenders.length > 0) {
          // Replace existing audio track
          console.log('üîÑ Replacing audio track using sender.replaceTrack...');
          await audioSenders[0].replaceTrack(newAudioTrack);
          console.log('‚úÖ Audio track replaced successfully');
        } else {
          // No sender found, add new track
          console.log('üîÑ No audio sender found, adding new track...');
          peerConnectionRef.current.addTrack(newAudioTrack, newStream);
        }
        
        // Stop old tracks
        localStreamRef.current.getTracks().forEach(track => {
          if (track !== newAudioTrack) {
            track.stop();
          }
        });
        
        // Monitor new track
        newAudioTrack.onended = () => {
          console.warn('‚ö†Ô∏è Local audio track ended again, attempting to re-capture...');
          reCaptureLocalAudio();
        };
        
        // Update local stream ref
        localStreamRef.current = newStream;
        if (localVideoRef.current) {
          localVideoRef.current.srcObject = newStream;
        }
        
        // Trigger renegotiation if connection is stable
        if (peerConnectionRef.current.signalingState === 'stable') {
          console.log('üîÑ Triggering renegotiation for track replacement...');
          const offer = await peerConnectionRef.current.createOffer();
          await peerConnectionRef.current.setLocalDescription(offer);
          
          const targetUserId = activeCall?.userId;
          if (targetUserId && socket) {
            socket.emit('renegotiate', {
              to: targetUserId,
              offer: offer
            });
            console.log('üì§ Sent renegotiation offer for local audio re-capture');
          }
        }
        
        console.log('‚úÖ Local audio re-captured and track replaced');
        toast.success('Microphone reconnected');
      }
    } catch (error) {
      console.error('‚ùå Failed to re-capture local audio:', error);
      toast.error('Failed to re-capture microphone');
      
      // Retry after a delay
      setTimeout(() => {
        if (activeCall && peerConnectionRef.current) {
          console.log('üîÑ Retrying local audio re-capture...');
          reCaptureLocalAudio();
        }
      }, 3000);
    }
  };

  // Start call timer
  const startCallTimer = () => {
    if (callTimerRef.current) {
      clearInterval(callTimerRef.current);
    }
    setCallDuration(0);
    callTimerRef.current = setInterval(() => {
      setCallDuration(prev => prev + 1);
    }, 1000);
  };

  // Stop call timer
  const stopCallTimer = () => {
    if (callTimerRef.current) {
      clearInterval(callTimerRef.current);
      callTimerRef.current = null;
    }
    setCallDuration(0);
  };

  // Format call duration
  const formatCallDuration = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // Initiate call
  const initiateCall = async (userId, userName, userProfilePic) => {
    if (!socket) {
      toast.error('Not connected to server');
      return;
    }

    // Verify HTTPS (required for WebRTC and getUserMedia)
    const isSecureContext = window.isSecureContext || 
                            location.protocol === 'https:' || 
                            location.hostname === 'localhost' || 
                            location.hostname === '127.0.0.1';
    
    if (!isSecureContext) {
      toast.error('WebRTC requires HTTPS connection (or localhost)');
      return;
    }

    // Check if getUserMedia is available
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      toast.error('Microphone access not supported in this browser');
      return;
    }

    try {
      setCallStatus('calling');
      callStatusRef.current = 'calling';
      setActiveCall({ userId, userName, userProfilePic, isIncoming: false });

      // Get user media (audio only for VoIP)
      // For mobile/WebView, request with specific constraints
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          // For Android WebView, sometimes need to specify sample rate
          ...(isMobile && {
            sampleRate: 48000,
            channelCount: 1
          })
        },
        video: false
      };

      console.log('üé§ Requesting microphone access...');
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log('‚úÖ Microphone access granted, stream obtained:', stream);
      
      // Monitor local tracks for automatic re-capture if they end
      stream.getAudioTracks().forEach(track => {
        track.onended = () => {
          console.warn('‚ö†Ô∏è Local audio track ended, attempting to re-capture...');
          reCaptureLocalAudio();
        };
      });
      
      localStreamRef.current = stream;
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        // For mobile, ensure audio element is set up correctly
        if (isMobile || isWebView) {
          localVideoRef.current.setAttribute('playsinline', 'true');
          localVideoRef.current.setAttribute('webkit-playsinline', 'true');
          localVideoRef.current.muted = true; // Local audio should be muted to avoid feedback
        }
      }

      // Create peer connection
      const pc = await createPeerConnection();

      // Create offer with better configuration for cross-device
      const offerOptions = {
        offerToReceiveAudio: true,
        offerToReceiveVideo: false,
        iceRestart: false
      };
      
      const offer = await pc.createOffer(offerOptions);
      await pc.setLocalDescription(offer);
      
      console.log('üì§ Created offer, local description set');
      console.log('üì§ Offer SDP type:', offer.type);
      console.log('üì§ ICE candidates in offer:', offer.sdp?.match(/a=candidate:/g)?.length || 0);

      // Send call request
      socket.emit('call-user', {
        to: userId,
        offer: offer
      });

      // Set timeout for call (30 seconds)
      const timeoutId = setTimeout(() => {
        if (callStatusRef.current === 'calling') {
          endCall();
          toast.error('Call timeout - User not available');
        }
      }, 30000);
      
      // Store timeout ID to clear if call connects
      if (peerConnectionRef.current) {
        peerConnectionRef.current._callTimeout = timeoutId;
      }

    } catch (error) {
      console.error('‚ùå Error initiating call:', error);
      
      // Better error messages for microphone permissions
      let errorMessage = 'Failed to start call. ';
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        errorMessage = 'Microphone permission denied. Please allow microphone access in your browser/app settings.';
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        errorMessage = 'No microphone found. Please connect a microphone.';
      } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
        errorMessage = 'Microphone is being used by another app. Please close other apps using the microphone.';
      } else if (error.name === 'OverconstrainedError') {
        errorMessage = 'Microphone constraints not supported. Trying with default settings...';
        // Try with simpler constraints
        try {
          const fallbackStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
          localStreamRef.current = fallbackStream;
          console.log('‚úÖ Fallback microphone access successful');
          // Continue with call setup...
          const pc = createPeerConnection();
          const offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
          await pc.setLocalDescription(offer);
          socket.emit('call-user', { to: userId, offer: offer });
          return;
        } catch (fallbackError) {
          errorMessage = 'Failed to access microphone. Please check permissions.';
        }
      } else {
        errorMessage += 'Please check microphone permissions and try again.';
      }
      
      toast.error(errorMessage);
      endCall();
    }
  };

  // Accept incoming call
  const acceptCall = async () => {
    if (!incomingCall || !socket) return;

    // Verify HTTPS (required for WebRTC and getUserMedia)
    const isSecureContext = window.isSecureContext || 
                            location.protocol === 'https:' || 
                            location.hostname === 'localhost' || 
                            location.hostname === '127.0.0.1';
    
    if (!isSecureContext) {
      toast.error('WebRTC requires HTTPS connection (or localhost)');
      setIncomingCall(null);
      return;
    }

    // Check if getUserMedia is available
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      toast.error('Microphone access not supported in this browser');
      setIncomingCall(null);
      return;
    }

    try {
      // Get user media with mobile-specific constraints
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          ...(isMobile && {
            sampleRate: 48000,
            channelCount: 1
          })
        },
        video: false
      };

      console.log('üé§ Requesting microphone access to accept call...');
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log('‚úÖ Microphone access granted, stream obtained:', stream);
      
      // Monitor local tracks for automatic re-capture if they end
      stream.getAudioTracks().forEach(track => {
        track.onended = () => {
          console.warn('‚ö†Ô∏è Local audio track ended, attempting to re-capture...');
          reCaptureLocalAudio();
        };
      });
      
      localStreamRef.current = stream;
      if (localVideoRef.current) {
        localVideoRef.current.srcObject = stream;
        // For mobile, ensure audio element is set up correctly
        if (isMobile || isWebView) {
          localVideoRef.current.setAttribute('playsinline', 'true');
          localVideoRef.current.setAttribute('webkit-playsinline', 'true');
          localVideoRef.current.muted = true; // Local audio should be muted to avoid feedback
        }
      }

      // Create peer connection
      const pc = await createPeerConnection();

      // Set remote description from offer
      if (incomingCall.offer) {
        await pc.setRemoteDescription(new RTCSessionDescription(incomingCall.offer));
        console.log('üì• Set remote description (offer)');
        
        // Create answer with better configuration
        const answerOptions = {
          offerToReceiveAudio: true,
          offerToReceiveVideo: false
        };
        
        const answer = await pc.createAnswer(answerOptions);
        await pc.setLocalDescription(answer);
        
        console.log('üì§ Created answer, local description set');
        console.log('üì§ Answer SDP type:', answer.type);
        console.log('üì§ ICE candidates in answer:', answer.sdp?.match(/a=candidate:/g)?.length || 0);

        // Send answer
        socket.emit('call-answer', {
          to: incomingCall.from,
          answer: answer
        });
      }

      setCallStatus('active');
      callStatusRef.current = 'active';
      setActiveCall({
        userId: incomingCall.from,
        userName: incomingCall.userName,
        userProfilePic: incomingCall.userProfilePic,
        isIncoming: true
      });
      setIncomingCall(null);
      startCallTimer();

      // Ensure remote audio element is ready and not muted
      // Check multiple times as stream might arrive later
      const checkAndPlayAudio = () => {
        if (remoteVideoRef.current) {
          remoteVideoRef.current.muted = false;
          remoteVideoRef.current.volume = 1.0;
          
          if (remoteVideoRef.current.srcObject) {
            const tracks = remoteVideoRef.current.srcObject.getTracks();
            console.log('üîä Checking audio after accept:', {
              hasStream: !!remoteVideoRef.current.srcObject,
              tracks: tracks.length,
              trackEnabled: tracks.length > 0 ? tracks[0].enabled : false
            });
            
            remoteVideoRef.current.play().then(() => {
              console.log('‚úÖ Remote audio playing after accept');
            }).catch(err => {
              console.log('Remote audio play attempt after accept:', err);
            });
          } else {
            console.log('‚è≥ Waiting for remote stream...');
          }
        }
      };
      
      // Check immediately and then retry
      checkAndPlayAudio();
      setTimeout(checkAndPlayAudio, 500);
      setTimeout(checkAndPlayAudio, 1000);
      setTimeout(checkAndPlayAudio, 2000);

      toast.success('Call connected');
    } catch (error) {
      console.error('‚ùå Error accepting call:', error);
      
      // Better error messages for microphone permissions
      let errorMessage = 'Failed to accept call. ';
      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        errorMessage = 'Microphone permission denied. Please allow microphone access in your browser/app settings.';
      } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        errorMessage = 'No microphone found. Please connect a microphone.';
      } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
        errorMessage = 'Microphone is being used by another app. Please close other apps using the microphone.';
      } else if (error.name === 'OverconstrainedError') {
        errorMessage = 'Microphone constraints not supported. Trying with default settings...';
        // Try with simpler constraints
        try {
          const fallbackStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
          localStreamRef.current = fallbackStream;
          console.log('‚úÖ Fallback microphone access successful');
          // Continue with call setup...
          const pc = createPeerConnection();
          if (incomingCall.offer) {
            await pc.setRemoteDescription(new RTCSessionDescription(incomingCall.offer));
            const answer = await pc.createAnswer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
            await pc.setLocalDescription(answer);
            socket.emit('call-answer', { to: incomingCall.from, answer: answer });
          }
          setCallStatus('active');
          callStatusRef.current = 'active';
          setActiveCall({
            userId: incomingCall.from,
            userName: incomingCall.userName,
            userProfilePic: incomingCall.userProfilePic,
            isIncoming: true
          });
          setIncomingCall(null);
          startCallTimer();
          toast.success('Call connected');
          return;
        } catch (fallbackError) {
          errorMessage = 'Failed to access microphone. Please check permissions.';
        }
      } else {
        errorMessage += 'Please check microphone permissions and try again.';
      }
      
      toast.error(errorMessage);
      setIncomingCall(null);
      endCall();
    }
  };

  // Reject incoming call
  const rejectCall = () => {
    if (!incomingCall || !socket) return;

    socket.emit('reject-call', {
      to: incomingCall.from
    });

    setIncomingCall(null);
    setCallStatus('idle');
  };

  // End call
  const endCall = () => {
    // Reset reconnect attempts
    reconnectAttemptsRef.current = 0;
    
    // Clear any playing check intervals
    if (remoteVideoRef.current && remoteVideoRef.current._playingCheck) {
      clearInterval(remoteVideoRef.current._playingCheck);
    }
    
    // Clear stream active checks
    if (remoteStreamRef.current && remoteStreamRef.current._activeCheck) {
      clearInterval(remoteStreamRef.current._activeCheck);
    }
    
    // Clear track monitor intervals
    if (remoteStreamRef.current) {
      remoteStreamRef.current.getTracks().forEach(track => {
        if (track._monitorInterval) {
          clearInterval(track._monitorInterval);
        }
      });
    }
    
    // Clear track monitor interval ref
    if (trackMonitorIntervalRef.current) {
      clearInterval(trackMonitorIntervalRef.current);
      trackMonitorIntervalRef.current = null;
    }
    
    // Disconnect Web Audio API
    if (audioSourceRef.current) {
      try {
        audioSourceRef.current.disconnect();
        audioSourceRef.current = null;
      } catch (err) {
        console.warn('Error disconnecting audio source:', err);
      }
    }
    
    // Close AudioContext
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close().catch(err => {
        console.warn('Error closing AudioContext:', err);
      });
      audioContextRef.current = null;
    }
    
    // Stop local stream
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      localStreamRef.current = null;
    }

    // Stop remote stream
    if (remoteStreamRef.current) {
      remoteStreamRef.current.getTracks().forEach(track => {
        track.stop();
        // Clean up WebView keep-alive flag
        if (track._webViewKeepAlive) {
          delete track._webViewKeepAlive;
        }
      });
      remoteStreamRef.current = null;
    }
    
    // Clean up WebView stream references
    if (window._activeWebRTCStreams) {
      window._activeWebRTCStreams.clear();
    }

    // Close peer connection
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      peerConnectionRef.current = null;
    }

    // Clear video refs
    if (localVideoRef.current) {
      localVideoRef.current.srcObject = null;
    }
    if (remoteVideoRef.current) {
      remoteVideoRef.current.srcObject = null;
    }

    // Emit end call event
    if (socket && activeCall) {
      socket.emit('end-call', {
        to: activeCall.userId
      });
    }

    // Reset state
    setActiveCall(null);
    setIncomingCall(null);
    setCallStatus('idle');
    callStatusRef.current = 'idle';
    setIsMuted(false);
    setIsVideoEnabled(false);
    stopCallTimer();
  };

  // Toggle mute
  const toggleMute = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getAudioTracks().forEach(track => {
        track.enabled = isMuted;
      });
      setIsMuted(!isMuted);
    }
  };

  // Toggle video (for future video call support)
  const toggleVideo = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getVideoTracks().forEach(track => {
        track.enabled = !isVideoEnabled;
      });
      setIsVideoEnabled(!isVideoEnabled);
    }
  };

  const value = {
    // State
    incomingCall,
    activeCall,
    callStatus,
    isMuted,
    isVideoEnabled,
    callDuration: formatCallDuration(callDuration),
    
    // Refs
    localVideoRef,
    remoteVideoRef,
    
    // Functions
    initiateCall,
    acceptCall,
    rejectCall,
    endCall,
    toggleMute,
    toggleVideo
  };

  return (
    <CallContext.Provider value={value}>
      {children}
    </CallContext.Provider>
  );
};

export const useCall = () => {
  const context = useContext(CallContext);
  if (!context) {
    throw new Error('useCall must be used within CallContextProvider');
  }
  return context;
};

